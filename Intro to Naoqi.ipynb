{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greetings! This is a python naoqi tutorial explaining the uses and protocol of naoqi's ALProxy module, which enables users to control Nao's with python scripts. Lets begin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and foremost, lets import ALProxy from naoqi so we can start working with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from naoqi import ALProxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To begin using all the modules installed on the Nao's, we first must create a \"Robot\" class, which requires an ip number and port number. One initializes this class to connect to a Nao that is currently connected to the wireless network your computer is connected to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the ip's of the NAOs in the Emergent Science Laboratory:\n",
    "    #hedwig - 165.106.241.201\n",
    "    #hoots - 165.106.241.202\n",
    "    #nyctimene - 165.106.241.203\n",
    "    #wol - 165.106.241.204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the modules/API's we would like to use by including them in the __init__() function. I included all the modules I used in my examples, but there exist many more useful ones in the Nao's latest documentation linked here: http://doc.aldebaran.com/2-1/naoqi/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Robot:\n",
    "    def __init__(self, ip, port):\n",
    "        self.ip = ip\n",
    "        self.port = port\n",
    "        self.tts = ALProxy(\"ALTextToSpeech\", ip, port)\n",
    "        self.rbd = ALProxy(\"ALRedBallDetection\", ip, port)\n",
    "        #self.extr = ALProxy(\"ALExtractor\", ip, port)\n",
    "        #self.camera = ALProxy(\"ALPhotoCapture\", ip, port) \n",
    "        self.visual = ALProxy(\"ALVideoDevice\", ip, port)\n",
    "        self.motion = ALProxy(\"ALMotion\", ip, port)\n",
    "        self.life = ALProxy(\"ALAutonomousLife\", ip, port)\n",
    "        self.posture = ALProxy(\"ALRobotPosture\", ip, port)\n",
    "        self.behave = ALProxy(\"ALBehaviorManager\", ip, port)\n",
    "        self.tracker = ALProxy(\"ALTracker\", ip, port)\n",
    "        self.tts.say(\"sure\")\n",
    "        self.life.setState(\"disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize a robot class now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wol = Robot(\"wol\",9559)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTextToSpeech has a self explanatory function named say(), which has the Nao say the input string. Below is a function definition using it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def say(self, text):\n",
    "        self.tts.say(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALMotion contains many functions pretaining to the robot's individual movements of its joints and body parts. Before calling any movement functions however, one must turn on the motor for the specific joint(s) first with setStiffnesses(). This function takes the name of the joint or body part you want to address as a string, and the percentage of power you want the motor to run on as values between 0 and 1 as parameters. To prevent overheating, it is suggested to turn off the selected motors after you are done moving the Nao. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For these functions and many other modules' functions, adding a timed halt before the execution of the next line is necessary for functions to finish. For example, assuming a sitting position takes more than a few milliseconds for the Nao to complete, so a 10 second halt of the code is recommended for posture changes. This is why we must import python's time package to accomplish this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a move_head() function with takes in a list of two floats, floats that range from -1 to 1, and set the robot's two head joints, HeadYaw and HeadPitch, to those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def move_head(self, newAngles):\n",
    "        #newAngles = [HeadYaw value, HeadPitch value]\n",
    "        self.motion.setStiffnesses(\"Head\", 1.0)\n",
    "        self.setAngles(\"HeadYaw\", newAngles[0], 0.1)\n",
    "        self.setAngles(\"HeadPitch\", newAngles[1], 0.1)\n",
    "        time.sleep(1.0)\n",
    "        print (\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also wrote a function that sets the Nao's head at neutral position to more easily accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def set_neutral(self):\n",
    "        self.motion.setStiffnesses(\"Head\", 1.0)\n",
    "        self.motion.setAngles(\"HeadPitch\", 0, 0.1)\n",
    "        self.motion.setAngles(\"HeadYaw\", 0, 0.1)\n",
    "        time.sleep(3.0)\n",
    "        self.motion.setStiffnesses(\"Head\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ALTracker module provides the user with a set of functions enabling the Nao to register and remember an object, and track the object with its head when the object is within its field of vision. registerTarget() takes the desired object to be remembered's name as a string and its diameter in meters as parameters. tracker() simply takes the name of your registered object as a string and begins to track it. I wrote a function track_ball() which compiles the two functions together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def track_ball(self, target_name, diameter):\n",
    "        self.tracker.registerTarget(target_name, diameter)\n",
    "        time.sleep(3.0)\n",
    "        temp = self.tracker.getRegisteredTargets()\n",
    "        time.sleep(1.0)\n",
    "        print temp\n",
    "        temp2 = self.tracker.getMode()\n",
    "        print \"in mode: \" + temp2\n",
    "        self.motion.setStiffnesses(\"Head\", 1.0)\n",
    "        self.tracker.track(target_name)\n",
    "        time.sleep(10.0)\n",
    "        self.tracker.stopTracker()\n",
    "        self.motion.setStiffnesses(\"Head\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Image\n",
    "import vision_definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subscribe() initializes the Nao's camera with specific settings passed through as parameters. It takes in the name of the image, the desired resolution you would like the Nao to take photos in, what colorspace to use, and at what frames per second (fps). These settings have been associated with ID numbers notated here: http://doc.aldebaran.com/2-1/naoqi/vision/alvideodevice-api.html#cameraresolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subscribe(pic_name, resolution, colorspace, fps)\n",
    "testClient = wol.visual.subscribe(\"python_client\", 8, 11, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getImageRemote() takes the initialized camera variable as input and takes a photo with the desired settings. To construct this photo as a variable, we must use the function, .frombytes() from python's Image package. frombytes() requires an image's width, height, array, and desired colorspace to construct a photo, and we can grab this data by calling the first, second, and seventh item of the variable created with getImageRemote(), like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testImage = wol.visual.getImageRemote(testClient)\n",
    "testImageWidth = testImage[0]\n",
    "testImageHeight = testImage[1]\n",
    "testArray = testImage[6]\n",
    "#frombytes(colorspace, (imageWidth, imageHeight), array)\n",
    "testImg = Image.frombytes(\"RGB\", (testImageWidth, testImageHeight), testArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, to actually save the photo as a file of a desired photo file type in the jupyter notebook's directory, we use Image's .save() function. It takes in the desired name of the photo plus the photo file type after it as a string, and the name of the photo file type as another string as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testImg.save(\"testPhoto123.jpeg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from unsubscribe() simply uninitializes a camera variable by passing the variable into this function as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wol.visual.unsubscribe(testClient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function save_photo() I wrote that combines all of these functions together to take a photo with the Nao and save it with the desired photo name as a string as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def save_photo(self, img_name): #takes 640x480 photo and saves to .py file directory\n",
    "        print \"taking photo: \" + img_name\n",
    "        vidClient = self.visual.subscribe(\"python_client\", 8, 11, 5) #initialize cam with settings\n",
    "        naoImage = self.visual.getImageRemote(vidClient) #taking photo\n",
    "        time.sleep(0.5)\n",
    "        self.visual.unsubscribe(vidClient) #un-initialize\n",
    "        imageWidth = naoImage[0]\n",
    "        imageHeight = naoImage[1]\n",
    "        array = naoImage[6]\n",
    "        img = Image.frombytes(\"RGB\", (imageWidth, imageHeight), array)\n",
    "        img.save(img_name + \".jpeg\", \"JPEG\")\n",
    "        print \"photo \" + img_name + \" saved!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For something a bit more complicated, here is the function, recognize_n_act(), which utilizes functions from ALMotion, ALVideoDevice, and ALTracker and showcases how all these modules can work in unison to accomplish a task. It set's the Nao's head to neutral, saves an image, then tracks the ball, says its found it, return the joint angles of its head, and stops tracking the ball. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def recognize_n_act(self, target_name, img_name):\n",
    "        #sets nao's head to neutral, saves an image, then tracks the ball,\n",
    "        #says its found it, return the joint angles of its head, and stops tracking\n",
    "        self.set_neutral()\n",
    "        time.sleep(1.0)\n",
    "        self.save_photo(img_name)\n",
    "        self.motion.setStiffnesses(\"Head\", 1.0)\n",
    "        self.tracker.track(target_name)\n",
    "        time.sleep(1.5)\n",
    "        self.tts.say(\"found \" + target_name)\n",
    "        temp3 = str(self.motion.getAngles(\"HeadYaw\", True))[1:-1]\n",
    "        temp4 = str(self.motion.getAngles(\"HeadPitch\", True))[1:-1]\n",
    "        fp = open(\"naoheadangles.txt\", \"a\")\n",
    "        fp.write(temp3 + \", \" + temp4 + \"\\n\") #writing angles into .txt file\n",
    "        fp.close()\n",
    "        time.sleep(0.5)\n",
    "        self.tracker.stopTracker()\n",
    "        self.motion.setStiffnesses(\"Head\", 0)\n",
    "        self.set_neutral()\n",
    "        #does all the work for me :3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In addition, I wrote an additional function, save_multiple_photos(), which calls recognize_n_act() a set number of times that you enter in as input in the function, and pauses and has the Nao ask the user to move the ball to a new location before it takes the next photo. This function comes in handy in the \"Intro to Conx\" tutorial for collecting training_set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def save_multiple_photos(self, target_name, img_name, amount):\n",
    "        counter = \"1\"\n",
    "        for index in range(0, amount):\n",
    "            self.recognize_n_act(target_name, img_name + counter)\n",
    "            if index == amount:\n",
    "                break\n",
    "            self.tts.say(\"move \" + target_name + \"to a new location\")\n",
    "            time.sleep(2.0)\n",
    "            self.tts.say(\"ready? okay\")\n",
    "            counter = str(int(counter) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This tutorial only goes through a few modules and now they work, however there exist many other modules available for use. Here is a small key they compiles the models for the most used functions in the tutorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#functions you'd like to know:\n",
    "    #getAngles(names, bool useSensors)\n",
    "    #setAngles(names, angles, fractionMaxSpeed)\n",
    "    #changeAngles(names, changes, fractionMaxSpeed)\n",
    "    #getSubscribersInfo() -- Gets the list of parameters for all the current subscribers (name, period and precision)\n",
    "    #getPostureList()\n",
    "    #goToPosture(name, speed)\n",
    "    #setState(name)\n",
    "    #frombytes(colorspace, (imageWidth, imageHeight), array)\n",
    "    #subscribe(pic_name, resolution, colorspace, fps)\n",
    "        #2 is 640x480, 3 is 1280x960, 8 is 40x30\n",
    "        #supports up to 30 fps\n",
    "        #dont change colorspace, its on standard RGB colorspace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
