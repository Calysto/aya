{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greetings! This is a conx user tutorial that will explain basic protocol on how to create deep machine learning networks, train them on examples, and test the network.\n",
    "\n",
    "So lets jump right into it. First step to using conx's network class is to import it...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 950 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from conx import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the Network class, its time to initialize a new class. Creating a new class requires 3 parameters: the number of inputs into the network, the unit size of the hidden layer, and the number of outputs expected.\n",
    "\n",
    "Lets try it now. These two networks are ones we will use later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here is the model:\n",
    "#new_network = Network(inputs, hidden layer, outputs)\n",
    "\n",
    "snetx = Network(1200, 50, 1)\n",
    "cnetx = Network(1200, 50, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since conx networks can only take float values between 0 and 1 as inputs, next one must decide what he or she wants the network to learn and how to represent that with only float values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example project, lets have a Nao be able to recognize where a bright orange ball is and look towards it without using its tracking modules. To accomplish this, we will first have the robot take photos of the ball with its head's joint angles both set to 0 in neutral position, track the ball, and record the joint angle values in a text document. Then we will convert the photos into arrays, pair them up with their respective angle values in a training set, and pass them through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, lets import the myNao.py file and use the photo taking and tracking function written in the My Nao tutorial to accomplish the first half of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from myNao import Robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_multiple_photos(target name, image name, desired # of photos taken)\n",
    "\n",
    "save_multiple_photos(\"RedBall\", \"ExamplePhoto\", 5)\n",
    "\n",
    "#Keep the ball in position until the console says the photo has been \n",
    "#taken. Then the nao will ask you to move it into a new location for the \n",
    "#next photo. It continues this cycle until the desired amount of photos \n",
    "#have been taken.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Although the example line calls to take 5 demo photos, an optimal training set for a conx network will need at least more than 30 items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to convert the photos into arrays, pair them up with their respective angles, and group all the items together in a training set. To convert photos into arrays, we will need python's \"Image\" package, which lets the user open, save, and construct photos, and python's \"numpy\" package, which enables the creation and manipulation of arrays. To save the arrays as theano variables, we will need theano's config, and shared modules as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import Image\n",
    "from theano import config, shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conx networks only accept one dimensional arrays with values ranging between 0 and 1. Since the photos the example code takes with the Nao are in RGB colorscale, they are considered 3D arrays. Black and white photos are typically converted into 2D arrays. Here are some helpful numpy array manipulation functions you will need to convert the 3D arrays into 1D arrays.\n",
    "\n",
    "Note: Product of reshape arguments should be equal to length of array which you changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grayscale(pic): #converts 30x40 RGB photos into grayscale (3D to 2D)\n",
    "    bwpic = pic.convert('L')\n",
    "    pic_array = np.asarray(bwpic, dtype=config.floatX).reshape((bwpic.size[1],bwpic.size[0]))\n",
    "    return pic_array\n",
    "\n",
    "def vectorizer(array): #converts 30x40 grayscale photos to vectors (2D to 1D)\n",
    "    v = array.flatten()\n",
    "    return v\n",
    "\n",
    "def matrixer(array): #converts 1D vectors into 2D arrays\n",
    "    twoD = np.reshape(array, (-1, 2))\n",
    "    return twoD\n",
    "\n",
    "def twoD_arrayifier(arr, h, w): #3D to 2D function that gives option of height and width of new array\n",
    "    \"\"\"\n",
    "    Return an array of shape (h, w) where\n",
    "    h * w = arr.size\n",
    "\n",
    "    If arr is of shape (n, nrows, ncols), n sublocks of shape (nrows, ncols),\n",
    "    then the returned array preserves the \"physical\" layout of the sublocks.\n",
    "    \"\"\"\n",
    "    n, nrows, ncols = arr.shape\n",
    "    return (arr.reshape(h//nrows, -1, nrows, ncols)\n",
    "               .swapaxes(1,2)\n",
    "               .reshape(h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, by calling grayscale(), then vectorizer(), then dividing the values in the array by 255 on the photo you have opened and saved to a variable, the array will be compatible with conx, or \"conx-ready\".\n",
    "\n",
    "ex code:\n",
    "\n",
    "pic = Image.open(photoname)\n",
    "\n",
    "array = vectorizer(grayscale(pic)) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here is an algorithm that completes this next step..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataset_maker(photoName, AnglesFile, amount):\n",
    "    #returns dataset list containing tuples of a pic_array and a list of\n",
    "    #the HeadYaw & HeadPitch angle values in radians.\n",
    "    #(pic_array(), array([HeadYaw, HeadPitch]))\n",
    "    dataset = []\n",
    "    jointAngleValues = open(AnglesFile,'r').read().splitlines()\n",
    "    arrays = []\n",
    "    temp = []\n",
    "    headAngles = []\n",
    "    counter = \"1\"\n",
    "    for index in range(0, amount):\n",
    "        pic = Image.open(photoName + counter + \".jpeg\")  \n",
    "        arrays.append(vectorizer(grayscale(pic))/255) #gotta add the photo array's joint angle values too\n",
    "        counter = str(int(counter) + 1)\n",
    "    for i in range(0, len(jointAngleValues)): #for each angle pair...\n",
    "        x = 0\n",
    "        previous_slice = 0\n",
    "        while x <= len(jointAngleValues[i]): #for each character in angle pair...\n",
    "            if x == len(jointAngleValues[i]):\n",
    "                temp.append((float(jointAngleValues[i][previous_slice:x])+1)/2) #finish off the pair of angles\n",
    "                headAngles.append(temp) #add em to headAngles list\n",
    "            elif jointAngleValues[i][x] == \",\":\n",
    "                temp = [((float(jointAngleValues[i][previous_slice:x]))+1)/2]\n",
    "                x += 2 #hop over space\n",
    "                previous_slice = x\n",
    "            x += 1 #increment counter\n",
    "    for i in range(0, amount):\n",
    "        #a = np.array(headAngles[i], dtype=config.floatX)\n",
    "        next_input = [arrays[i], headAngles[i]] #create tuple of data\n",
    "        dataset.append(next_input) #add tuple to the dataset\n",
    "    return dataset #add class labels as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here is an algorithm that just notes whether the ball is on the left or right side of the photo with a boolean value of 0 or 1 and pairs this value up with the photo arrays instead of the angles, to show that a simpler task can be done with conx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def S_dataset_maker(photoName, AnglesFile, amount):\n",
    "    #returns dataset list containing tuples of a pic_array and a list of\n",
    "    #the HeadYaw & HeadPitch angle values in radians.\n",
    "    #[(pic_array1(), [boolean]), (pic_array2(), [boolean]),...]\n",
    "    dataset = []\n",
    "    jointAngleValues = open(AnglesFile,'r').read().splitlines()\n",
    "    arrays = []\n",
    "    headValues = []\n",
    "    counter = \"1\"\n",
    "    for index in range(0, amount):\n",
    "        pic = Image.open(photoName + counter + \".jpeg\")  \n",
    "        arrays.append(vectorizer(grayscale(pic))/255) #gotta add the photo array's joint angle values too\n",
    "        counter = str(int(counter) + 1)\n",
    "    for i in range(0, len(jointAngleValues)):\n",
    "        if jointAngleValues[i][0] == \"-\": #if HeadYaw is negative...\n",
    "            temp = [1]  #head is turned to the right/ball is in right side of photo\n",
    "            headValues.append(temp)\n",
    "        else:\n",
    "            temp = [0]  #head is turned to the left/ball is in left side of photo\n",
    "            headValues.append(temp)\n",
    "    for k in range(0, amount):\n",
    "        next_input = (arrays[k], headValues[k])\n",
    "        dataset.append(next_input)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to create our training datasets. ets use some photos I took already for the training sets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S_training_set = S_dataset_maker(\"naoBallPhoto\", \"naoheadangles.txt\", 35)\n",
    "\n",
    "C_training_set = dataset_maker(\"naoBallPhoto\", \"naoheadangles.txt\", 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to pass these training sets through the networks, we need to set the initialized network's input to be the list variable you created from dataset_maker() or S_dataset_maker(), and then call train() on the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "network.train() has a few optional parameters you can take advantage of. You can select after how many full runs through the training set, or epochs, the system will print out its TSS error and percent accuracy with report_rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set the margin of error the system will allow with its predictions with tolerance. Note that the optimal tolerance for training a dataset will always be dependent on what the goal of the training is. For instance, since the S_training_set only tells whether the ball is on the left or right side of the photo with a boolean value, any float value the system returns that is less than 0.5 can be considered 0 and greater than 0.5 can be considered 1. So a tolerance of 0.4 is acceptable in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set your desired prediction accuracy percentage as well with stop_percentage, which provides the threshold for when the network should stop training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set the maximum amount of epochs the train() call will go through with max_training_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check what the training settings are: run network.settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_function': <theano.tensor.elemwise.Elemwise at 0x7f77290b2110>,\n",
       " 'epsilon': 0.1,\n",
       " 'max_training_epochs': 5000,\n",
       " 'momentum': 0.9,\n",
       " 'report_rate': 500,\n",
       " 'stop_percentage': 1.0,\n",
       " 'tolerance': 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snetx.settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to call train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training for max trails: 5000 ...\n",
      "Epoch: 0 TSS error: 11.4807234672 %correct: 0.4\n",
      "--------------------------------------------------\n",
      "Epoch: 73 TSS error: 0.388495914765 %correct: 1.0\n"
     ]
    }
   ],
   "source": [
    "snetx.set_inputs(S_training_set)\n",
    "snetx.reset()\n",
    "snetx.train(report_rate = 100, tolerance = 0.3, stop_percentage=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training for max trails: 5000 ...\n",
      "Epoch: 0 TSS error: 10.6444192156 %correct: 0.0\n",
      "--------------------------------------------------\n",
      "Epoch: 232 TSS error: 0.0424394530855 %correct: 1.0\n"
     ]
    }
   ],
   "source": [
    "cnetx.set_inputs(C_training_set)\n",
    "cnetx.reset()\n",
    "cnetx.train(report_rate = 500, tolerance = 0.1, stop_percentage = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully trained our networks, time to test them with these prediction functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def S_predict(pic_array):\n",
    "    #accepts 1D photo array as input and predicts whether the ball in\n",
    "    #the photo is in the left or right half of the photo, returning a \n",
    "    #boolean 0 or 1 (0 = left, 1 = right)\n",
    "    y = snetx.propagate(pic_array)\n",
    "    if 1 - y[0] < y[0]:\n",
    "        return \"the ball is on the right side of the photo\"\n",
    "    else:\n",
    "        return \"the ball is on the left side of the photo\"\n",
    "\n",
    "def C_predict(pic_array):\n",
    "    #takes in a 1D photo array and predicts the angles the head joints\n",
    "    #should assume if the robot was looking directly at the ball in the\n",
    "    #photo. Also scales the output back into the proper -1 to 1 range.\n",
    "    x = cnetx.propagate(pic_array)\n",
    "    return [(x[0] * 2)-1, (x[1] *2)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"hardware_headjoint_3.3.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to test the trained system with some of the training data photos...\n",
    "\n",
    "Note: The head's joint angles are recorded in radians, ranging between -1:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"naoBallPhoto23.jpeg\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = Image.open(\"naoBallPhoto23.jpeg\")\n",
    "z = vectorizer(grayscale(y))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ball is on the left side of the photo\n"
     ]
    }
   ],
   "source": [
    "x = S_predict(z)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.29144561290740967, -0.19938766956329346]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_predict(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"naoBallPhoto17.jpeg\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o = Image.open(\"naoBallPhoto17.jpeg\")\n",
    "p = vectorizer(grayscale(o))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ball is on the right side of the photo\n"
     ]
    }
   ],
   "source": [
    "x = S_predict(p)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.26814043521881104, 0.18113255500793457]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_predict(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"naoBallPhoto11.jpeg\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = Image.open(\"naoBallPhoto11.jpeg\")\n",
    "w = vectorizer(grayscale(q))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ball is on the left side of the photo\n"
     ]
    }
   ],
   "source": [
    "x = S_predict(w)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00073981285095214844, 0.020813941955566406]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_predict(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! Looks good! For the final test, lets take a brand new photo with the Nao, and test whether our networks will provide some accurate predictions...\n",
    "\n",
    "To do so, we will call C_predict() and S_predict() and then use the move_head() and say() functions, which will take the predict() outputs and either sets the nao's head joint to the predicted angles or says whether the ball is on the left or right side of its view, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make a robot class first, so lets use Wol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wol = Robot('wol',9559)\n",
    "wol.life.setState(\"disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Wol should take a photo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking photo: demoPhoto1\n",
      "photo demoPhoto1 saved!\n"
     ]
    }
   ],
   "source": [
    "img_name = \"demoPhoto1\"\n",
    "wol.set_neutral()\n",
    "wol.save_photo(img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we open up the photo, convert it to be conx-ready, and call the predict() functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pic = Image.open(img_name + \".jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"demoPhoto1.jpeg\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = vectorizer(grayscale(pic))/255\n",
    "C_newAngles = C_predict(array)\n",
    "S_verdict = S_predict(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test what we got..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wol.say(S_verdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "wol.move_head(C_newAngles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Wol successfuly could tell if the ball was on the left or right side of its view and moved its head to look at the ball, CONGRATULATIONS! It works!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
